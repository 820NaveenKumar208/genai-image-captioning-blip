## Prototype Development for Image Captioning Using the BLIP Model and Gradio Framework

### AIM:
To design and deploy a prototype application for image captioning by utilizing the BLIP image-captioning model and integrating it with the Gradio UI framework for user interaction and evaluation.

### PROBLEM STATEMENT:

### DESIGN STEPS:

#### STEP 1:
Import the necessary libraries such as Gradio, Requests, and other utility modules for handling images and API communication.
#### STEP 2:
Define a function get_completion() to send image data to the BLIP API endpoint and receive the generated caption response.
#### STEP 3:
Create a helper function image_to_base64_str() to convert uploaded images into base64 strings compatible with the API request format.
#### STEP 4:
Develop a main function captioner(image) that processes the image through the BLIP model and retrieves the generated caption.

#### STEP 5:
Build a Gradio interface with gr.Interface(), allowing users to upload an image, display captions, and visualize example outputs.

### PROGRAM:
```
import os
import io
import IPython.display
from PIL import Image
import base64 
from dotenv import load_dotenv, find_dotenv
_ = load_dotenv(find_dotenv()) # read local .env file
hf_api_key = os.environ['HF_API_KEY']

# Helper functions
import requests, json

#Image-to-text endpoint
def get_completion(inputs, parameters=None, ENDPOINT_URL=os.environ['HF_API_ITT_BASE']):
    headers = {
      "Authorization": f"Bearer {hf_api_key}",
      "Content-Type": "application/json"
    }
    data = { "inputs": inputs }
    if parameters is not None:
        data.update({"parameters": parameters})
    response = requests.request("POST",
                                ENDPOINT_URL,
                                headers=headers,
                                data=json.dumps(data))
    return json.loads(response.content.decode("utf-8"))

image_url = "https://www.telefonica.com/en/wp-content/uploads/sites/5/2023/07/differences-robotis-ia.jpg"
display(IPython.display.Image(url=image_url))
get_completion(image_url)

### OUTPUT1

import gradio as gr 

def image_to_base64_str(pil_image):
    byte_arr = io.BytesIO()
    pil_image.save(byte_arr, format='PNG')
    byte_arr = byte_arr.getvalue()
    return str(base64.b64encode(byte_arr).decode('utf-8'))

def captioner(image):
    base64_image = image_to_base64_str(image)
    result = get_completion(base64_image)
    return result[0]['generated_text']

gr.close_all()
demo = gr.Interface(fn=captioner,
                    inputs=[gr.Image(label="Upload image", type="pil")],
                    outputs=[gr.Textbox(label="Caption")],
                    title="Image Captioning with BLIP",
                    description="Caption any image using the BLIP model",
                    allow_flagging="never",
                    examples=["christmas_dog.jpeg", "bird_flight.jpeg", "cow.jpeg"])

demo.launch(share=True, server_port=int(os.environ['PORT1']))
```

### OUTPUT:
<img width="1920" height="1080" alt="image" src="https://github.com/user-attachments/assets/dcbd7137-6cf8-40a6-a5cb-09a4cca63606" />
<img width="1920" height="1080" alt="image" src="https://github.com/user-attachments/assets/787b7025-703b-412c-a780-e23247e5f501" />


### RESULT:
Thus, the image captioning application using the BLIP model was successfully developed and deployed with Gradio. The system efficiently generates descriptive captions for images, demonstrating the practical use of multimodal AI in automation and accessibility.
